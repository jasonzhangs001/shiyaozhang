<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Shiyao Zhang</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Shiyao Zhang</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="biography.html">Biography</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div>
<div class="menu-item"><a href="people.html">People</a></div>  
<div class="menu-item"><a href="project.html" class="current">Research Projects</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Shiyao Zhang</h1>
</div>

<h2>Research Projects</h2>

<h3>Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy</h3>

<div class="project-container">
  <div class="project-col video-col">
    <div class="video-embed">
      <iframe src="https://player.bilibili.com/player.html?isOutside=true&aid=115456857936044&bvid=BV1HSyUBJE6H&cid=33497353272&p=1&high_quality=1&autoplay=0" scrolling="no" frameborder="0" allowfullscreen="true"></iframe>
    </div>
  </div>
  <div class="project-col text-col">
    <p>In future intelligent transportation systems, autonomous cooperative planning (ACP), becomes a promising technique to increase the effectiveness and security of multi-vehicle interactions. However, multiple uncertainties cannot be fully addressed for existing ACP strategies, e.g. perception, planning, and communication uncertainties. To address these, a novel deep reinforcement learning-based autonomous cooperative planning (DRLACP) framework is proposed to tackle various uncertainties on cooperative motion planning schemes. Specifically, the soft actor-critic (SAC) with the implementation of gate recurrent units (GRUs) is adopted to learn the deterministic optimal time-varying actions with imperfect state information occurred by planning, communication, and perception uncertainties. In addition, the real-time actions of autonomous vehicles (AVs) are demonstrated via the Car Learning to Act (CARLA) simulation platform. Evaluation results show that the proposed DRLACP learns and performs cooperative planning effectively, which outperforms other baseline methods under different scenarios with imperfect AV state information.</p>
    <p>Authors: Shiyao Zhang, Liwei Deng, Shuyu Zhang, Weijie Yuan, and Hong Zhang</p>
    <p>Paper Link: <a href="https://ieeexplore.ieee.org/document/11204522/" target="_blank" rel="noopener noreferrer">https://ieeexplore.ieee.org/document/11204522/</a></p>
  </div>
  
</div>

</td>
</tr>
</table>

<style>
/* 两栏布局与视频响应式样式（在不破坏 jemdoc.css 的前提下最小覆盖） */
.project-container {
  display: flex;
  gap: 16px;
  align-items: flex-start;
  flex-wrap: wrap;
  margin-top: 8px;
}
.project-col {
  box-sizing: border-box;
}
.video-col {
  flex: 1 1 480px;
  min-width: 300px;
}
.text-col {
  flex: 1 1 360px;
  min-width: 280px;
}
.video-embed {
  position: relative;
  width: 100%;
  /* 16:9 比例 */
  padding-top: 56.25%;
  background: #000;
  overflow: hidden;
  border-radius: 4px;
}
.video-embed iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border: 0;
}
/* 移动端优化 */
@media (max-width: 768px) {
  .project-container {
    gap: 12px;
  }
}
</style>

</body>
</html>


