<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Shiyao Zhang</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Shiyao Zhang</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="biography.html">Biography</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div>
<div class="menu-item"><a href="people.html">People</a></div>  
<div class="menu-item"><a href="project.html" class="current">Research Projects</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Shiyao Zhang</h1>
</div>

<h2>Research Projects</h2>

<h3>Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy [RA-L 2025]</h3>

<div class="project-container">
  <div class="project-col video-col">
    <div class="video-embed">
      <iframe src="https://player.bilibili.com/player.html?isOutside=true&aid=115456857936044&bvid=BV1HSyUBJE6H&cid=33497353272&p=1&high_quality=1&autoplay=0" scrolling="no" frameborder="0" allowfullscreen="true"></iframe>
    </div>
  </div>
  <div class="project-col text-col">
    <p>In future intelligent transportation systems, autonomous cooperative planning (ACP), becomes a promising technique to increase the effectiveness and security of multi-vehicle interactions. However, multiple uncertainties cannot be fully addressed for existing ACP strategies, e.g. perception, planning, and communication uncertainties. To address these, a novel deep reinforcement learning-based autonomous cooperative planning (DRLACP) framework is proposed to tackle various uncertainties on cooperative motion planning schemes. Specifically, the soft actor-critic (SAC) with the implementation of gate recurrent units (GRUs) is adopted to learn the deterministic optimal time-varying actions with imperfect state information occurred by planning, communication, and perception uncertainties. In addition, the real-time actions of autonomous vehicles (AVs) are demonstrated via the Car Learning to Act (CARLA) simulation platform. Evaluation results show that the proposed DRLACP learns and performs cooperative planning effectively, which outperforms other baseline methods under different scenarios with imperfect AV state information.</p>
    <p>Authors: Shiyao Zhang, Liwei Deng, Shuyu Zhang, Weijie Yuan, and Hong Zhang</p>
    <p>Paper Link: <a href="https://ieeexplore.ieee.org/document/11204522/" target="_blank" rel="noopener noreferrer">https://ieeexplore.ieee.org/document/11204522/</a></p>
  </div>
  
</div>

<h3>Spatial-Temporal Motion Prediction in Cooperative Autonomous Driving System [VTC-Spring 2025]</h3>

<div class="project-container">
  <div class="project-col video-col">
    <div class="video-embed">
      <iframe src="https://player.bilibili.com/player.html?isOutside=true&aid=115460985133046&bvid=BV18ZybBGEi3&cid=33517274665&p=1&high_quality=1&autoplay=0" scrolling="no" frameborder="no" allowfullscreen="true"></iframe>
    </div>
  </div>
  <div class="project-col text-col">
    <p>Cooperative autonomous driving (AD) systems have increasingly become key elements of future intelligent transportation systems owing to the provisioning of dependable, safe, and effective urban mobility operations. In particular, the utilization of motion prediction can contribute to achieving a high-performance cooperative AD planning strategy of the vehicle platoon system. However, realizing accurate spatial-temporal motion prediction is a challenge since most existing work unilaterally considers the spatial or temporal feature in predicting vehicle motion trajectories. To address the problem, we design a novel spatial-temporal Transformer (ST-Transformer) motion prediction model to predict vehicle motion trajectories with highfidelity simulator. In particular, we integrate both the convolutional and transformer-based networks to capture the spatial-temporal feature of vehicle states. Case studies demonstrate the superiority of the proposed model in predicting autonomous vehicle (AV) trajectories over the existing baseline models, which can greatly support AV motion planning tasks.</p>
    <p>Authors: Shiyao Zhang, Shuyu Zhang, Song Wang, and Shuangyang Li</p>
    <p>Paper Link: <a href="https://ieeexplore.ieee.org/document/11174822" target="_blank" rel="noopener noreferrer">https://ieeexplore.ieee.org/document/11174822</a></p>
  </div>
  
</div>

<h3>Multi-Uncertainty Aware Autonomous Cooperative Planning [IROS 2024]</h3>

<div class="project-container">
  <div class="project-col video-col">
    <div class="video-embed">
      <iframe src="https://player.bilibili.com/player.html?isOutside=true&aid=114396286159495&bvid=BV1UpLLz2ENp&cid=29597634183&p=1&high_quality=1&autoplay=0" scrolling="no" frameborder="no" allowfullscreen="true"></iframe>
    </div>
  </div>
  <div class="project-col text-col">
    <p>Autonomous cooperative planning (ACP) is a promising technique to improve the efficiency and safety of multi-vehicle interactions for future intelligent transportation systems. However, realizing robust ACP is a challenge due to the aggregation of perception, motion, and communication uncertainties. This paper proposes a novel multi-uncertainty aware ACP (MUACP) framework that simultaneously accounts for multiple types of uncertainties via regularized cooperative model predictive control (RC-MPC). The regularizers and constraints for perception, motion, and communication are constructed according to the confidence levels, weather conditions, and outage probabilities, respectively. The effectiveness of the proposed method is evaluated in the Car Learning to Act (CARLA) simulation platform. Results demonstrate that the proposed MUACP efficiently performs cooperative formation in real time and outperforms other benchmark approaches in various scenarios under imperfect knowledge of the environment.</p>
    <p>Authors: Shiyao Zhang, He Li, Shengyu Zhang, Shuai Wang, Derrick Wing Kwan Ng, and Chengzhong Xu</p>
    <p>Paper Link: <a href="https://arxiv.org/abs/2411.00413" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2411.00413</a></p>
  </div>
  
</div>  

</td>
</tr>
</table>

<style>
/* 两栏布局与视频响应式样式（在不破坏 jemdoc.css 的前提下最小覆盖） */
.project-container {
  display: flex;
  gap: 16px;
  align-items: flex-start;
  flex-wrap: wrap;
  margin-top: 8px;
}
.project-col {
  box-sizing: border-box;
}
.video-col {
  flex: 1 1 480px;
  min-width: 300px;
}
.text-col {
  flex: 1 1 360px;
  min-width: 280px;
}
.video-embed {
  position: relative;
  width: 100%;
  /* 16:9 比例 */
  padding-top: 56.25%;
  background: #000;
  overflow: hidden;
  border-radius: 4px;
}
.video-embed iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border: 0;
}
/* 移动端优化 */
@media (max-width: 768px) {
  .project-container {
    gap: 12px;
  }
}
</style>

</body>
</html>


